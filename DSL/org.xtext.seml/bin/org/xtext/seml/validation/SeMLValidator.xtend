/*
 * generated by Xtext 2.10.0
 */
package org.xtext.seml.validation

import org.eclipse.xtext.validation.Check
import java.io.File
import org.xtext.seml.seML.SeMLPackage
import org.semanticweb.owlapi.model.OWLOntology
import org.semanticweb.owlapi.model.OWLOntologyManager
import org.semanticweb.owlapi.apibinding.OWLManager
import org.semanticweb.owlapi.model.OWLOntologyDocumentAlreadyExistsException
import org.semanticweb.owlapi.model.IRI
import org.semanticweb.owlapi.model.OWLDataFactory
import java.util.Set
import org.semanticweb.owlapi.reasoner.NodeSet
import org.semanticweb.owlapi.model.OWLClass
import com.clarkparsia.pellet.owlapi.PelletReasoner
import com.clarkparsia.pellet.owlapi.PelletReasonerFactory
import java.io.FileOutputStream
import java.io.PrintWriter
import org.eclipse.emf.ecore.resource.Resource
import org.eclipse.core.resources.ResourcesPlugin
import org.eclipse.core.runtime.Path
import org.semanticweb.owlapi.util.AutoIRIMapper
import org.eclipse.xtext.EcoreUtil2
import org.rass.ontologies.Ontologies
import org.rass.ontologies.MasterOntology
import org.xtext.seml.seML.Import
import java.io.IOException
import org.xtext.seml.seML.Relation
import org.eclipse.xtext.validation.CheckMode
import org.eclipse.xtext.validation.CheckType
import org.xtext.seml.seML.Model
import org.xtext.seml.seML.Individual
import java.text.DateFormat
import java.text.SimpleDateFormat
import org.xtext.seml.seML.MainModel
import org.xtext.seml.seML.MetaIndividual
import org.xtext.seml.seML.Component
import org.eclipse.emf.common.util.URI
import org.eclipse.emf.ecore.resource.ResourceSet
import java.io.FileInputStream
import java.io.BufferedReader
import java.io.InputStreamReader
import java.util.Collections
import java.util.Arrays
import org.xtext.seml.seML.ImportModel
import org.xtext.seml.seML.UseCharacteristic
import org.xtext.seml.seML.SeMLFactory

/**
 * This class contains custom validation rules. 
 *
 * See https://www.eclipse.org/Xtext/documentation/303_runtime_concepts.html#validation
 */
class SeMLValidator extends AbstractSeMLValidator {
	
	static String local_log = "Validator Log: ";

	
//	public static val INVALID_NAME = 'invalidName'
//
//	@Check
//	def checkGreetingStartsWithCapital(Greeting greeting) {
//		if (!Character.isUpperCase(greeting.name.charAt(0))) {
//			warning('Name should start with a capital', 
//					SeMLPackage.Literals.GREETING__NAME,
//					INVALID_NAME)
//		}
//	}

	public static val INVALID_NAME = 'invalidName'
	public static val GET_AXIOMS = "GetAxioms";
	public static val FIX_GENERATED = "FixGeneratedName";
	
	public static val GENERATE_SOLUTION = "GenerateSolution";
	


	
	@Check(CheckType.NORMAL) //only when saving
	def checkRelation(Relation rel){
		
	}
	
	@Check(CheckType.FAST) 
	def checkIndividual(Individual ind){
		if(ind.name.contains('#')) error("Individual name cannot contain \"#\"", SeMLPackage.Literals.ANY_INDIVIDUAL__NAME);
	}
	


	
	@Check(CheckType.FAST) 
	def checkModel(MainModel m){
		val String local_log = local_log + "[checkModel] ";
		var String[] inconsistencyReport = null;
		if(!checkImports(m)) return; //return if imports are invalid
		
		System.out.println(local_log + "Validating model...");
		
		val IndividualsList = EcoreUtil2.getAllContentsOfType(m, Individual);
		val RelationsList = EcoreUtil2.getAllContentsOfType(m, Relation);
		val UseList = EcoreUtil2.getAllContentsOfType(m, UseCharacteristic);
		
		try { //Load Master ontology file and initialize OWLAPI objects
			MasterOntology.loadMasterOntology(new File(Ontologies.GENfolder + Ontologies.masterNAME));
		} catch (IOException e) {
			error("Error loading master ontology file: " + e.message, m.imports.last, SeMLPackage.Literals.IMPORT__NAME); return;
		}			
		
		//Add all individuals to master ontology (check for duplicates)
		for(Individual i: IndividualsList){
			if(!MasterOntology.addIndividual(i)) {System.out.println(local_log + "Aborted. Model contains errors.");return;}

			/*inconsistencyReport =*/ 
			//if(inconsistencyReport.get(0) != null) {error(inconsistencyReport.get(0), i, SeMLPackage.Literals.ANY_INDIVIDUAL__NAME);return;}
		}
		
		//Add all relations to master ontology (check for inconsistency)
		for(Relation r: RelationsList){
			inconsistencyReport = MasterOntology.addRelation(r);
			if(inconsistencyReport != null) {error(inconsistencyReport.get(0), r, SeMLPackage.Literals.RELATION__OBJ);return;}
		}

		//Check if individuals that were created in Protégé meet theirs class's restrictions
		//Note: these errors are not detected before due to the Open World Assumption 
		val Model importRoot = getImportModel(m.eResource, Ontologies.GENfile_relpath); //Get model of generated file
		if(importRoot == null) {error("Error loading keywords file: " + Ontologies.GENfile_relpath, m.imports.last, SeMLPackage.Literals.IMPORT__NAME);return;}
		val MetaIndividualsList = (importRoot as ImportModel).metaIndividuals //Get all meta individuals
		MasterOntology.cacheIRIs(importRoot as ImportModel, IndividualsList); //must be done before calling checkRelationRestrictions
				
		for(MetaIndividual i: MetaIndividualsList){ 
			for(String s: i.cls){ //Iterate each class of an individual and check the restrictions of each class
				inconsistencyReport = MasterOntology.checkRelationRestrictions(s, i.iri);
				if(inconsistencyReport != null) {
					if(inconsistencyReport.get(1).empty){error("Instance: " +  i.iri + "\n" + inconsistencyReport, m.imports.last, SeMLPackage.Literals.IMPORT__NAME);}
					else error("Instance: " +  i.iri + "\n" + inconsistencyReport, m.imports.last, SeMLPackage.Literals.IMPORT__NAME, GENERATE_SOLUTION, inconsistencyReport.get(1));
					return;
				}
			}
		}
		
		//Perform the same Check for individuals created in the DSL
		for(Individual i: IndividualsList){
			for(Component c: i.cls){ //Check individual for multiple classes
				inconsistencyReport = MasterOntology.checkRelationRestrictions(c.iri, MasterOntology.OWL_Master + "#" + i.getName());
				if(inconsistencyReport != null) {
					if(inconsistencyReport.get(1).empty){ error(inconsistencyReport.get(0), i, SeMLPackage.Literals.ANY_INDIVIDUAL__NAME);}
					else error(inconsistencyReport.get(0), i, SeMLPackage.Literals.ANY_INDIVIDUAL__NAME, GENERATE_SOLUTION, inconsistencyReport.get(1)); //Create solution
					return;
				}
			}
		}
		
		//Perform the equivalent check for characteristics in use
		for(UseCharacteristic u: UseList){
			inconsistencyReport = MasterOntology.checkRelationRestrictions(u.name.iri, ""); //dummy individual ""
			if(inconsistencyReport != null) {
				if(inconsistencyReport.get(1).empty){ error("Characteristic: " +  u.name.iri + "\n" + inconsistencyReport.get(0), u, SeMLPackage.Literals.USE_CHARACTERISTIC__NAME);}
				else error("Characteristic: " +  u.name.iri + "\n" + inconsistencyReport.get(0), u, SeMLPackage.Literals.USE_CHARACTERISTIC__NAME, GENERATE_SOLUTION, inconsistencyReport.get(1));
				return;
			}
		}
		
		//Perform the same Check for the default characteristic
		inconsistencyReport = MasterOntology.checkRelationRestrictions(Ontologies.OWL_DefaultC, ""); //dummy individual ""
		if(inconsistencyReport != null) {
			if(inconsistencyReport.get(1).empty){ error("Default Characteristic\n" + inconsistencyReport.get(0), m.imports.last, SeMLPackage.Literals.IMPORT__NAME);}
			else error("Default Characteristic\n" + inconsistencyReport.get(0), m.imports.last, SeMLPackage.Literals.IMPORT__NAME, GENERATE_SOLUTION, inconsistencyReport.get(1));
			return;
		}
		
		
		System.out.println(local_log + "Done.");	
	}
	
	def Model getImportModel(Resource contextResource, String importURIAsString) {
		val URI importURI = URI?.createURI(importURIAsString)
		//System.out.println(importURI);
		val URI contextURI = contextResource?.getURI
		//System.out.println(contextURI);
		val URI resolvedURI = importURI?.resolve(contextURI)
		//System.out.println(resolvedURI);
		val ResourceSet contextResourceSet = contextResource?.resourceSet
		//System.out.println("hey");
		//contextResourceSet.allContents.forEach[ a | System.out.println(a)]
		val Resource resource = contextResourceSet?.getResource(resolvedURI, false)
		//System.out.println(resource.allContents.head);
		return resource?.allContents?.head as Model
		
		
	}
	
	/**
	 * Auxiliary function of checkModel, to check imports and create the master ontology
	 * 
	 * @param m		MainModel
	 * @return		True if imports are valid 
	 */
	def boolean checkImports(MainModel m){ //detects changes in Imported ontologies
		val String local_log = local_log + "[checkModelImports] ";
		var long mostRecentFile = 0;
	
		//Check if there are any imports
		if(m.imports.empty) return false;
		
		//Create imports paths list
		val String[] pathslist = newArrayOfSize(m.imports.length); var int cnt = 0;
		
		//Check if every file exists before proceeding
		for(i: m.imports){
			val File ontfile = new File(i.getName());
			if(!ontfile.exists || ontfile.isDirectory) {error("Ontology file was not found", i, SeMLPackage.Literals.IMPORT__NAME); return false;}
			if(mostRecentFile < ontfile.lastModified) mostRecentFile = ontfile.lastModified;
			pathslist.set(cnt++,i.getName());
		}
		Arrays.sort(pathslist); //Sort ontologies paths to compare them with the generated file's list
				
		//Generate paths for current SEML file and generated SEML file, for a given ontology
		Ontologies.populatePaths(m);
		
		//Check if generated file is up-to-date
		if(Ontologies.GENfile.exists && Ontologies.GENfile.file){ //Check if file exists
		
			//Check if generated file is older than the most recent ontology
			if(mostRecentFile.compareTo(Ontologies.GENfile.lastModified) < 0){
				
				try {
					//Check if every imported file matches exactly with the generated file summary
					val FileInputStream fis = new FileInputStream(Ontologies.GENfile); //Open generated file
					val BufferedReader br = new BufferedReader(new InputStreamReader(fis)); //Construct BufferedReader from InputStreamReader			 
					
					var String line = br.readLine(); cnt = 0;
					var int SourceFilesNo = Integer.valueOf(line.substring(Ontologies.GENfirstline.length));
					var boolean different = false;
					
					if(pathslist.size == SourceFilesNo){ //Check if number of source files matches
						while ((line = br.readLine()) != "*/") { //Read every line until the end of the commentary
							if(!pathslist.get(cnt++).equals(line)) different = true;
						}
						if(!different) {
							val File masterfile = new File(Ontologies.GENfolder + Ontologies.masterNAME);
							if(masterfile.exists && masterfile.file) {br.close(); return true;}
							else System.out.println(local_log + "Master Ontology file was deleted. Creating a new one...");	
						}
						else System.out.println(local_log + "Ontology sources have changed. Updating DSL keywords...");	
						
					} else System.out.println(local_log + "Number of ontology sources has changed. Updating DSL keywords...");	
					
					br.close();
				} catch (Exception e) {
					System.out.println(local_log + "Error while reading generated file: " + e.message);
					System.out.println(local_log + "Repairing file...");		   	
				}
				
			} else System.out.println(local_log + "Changes in ontologies detected. Updating DSL keywords...");	
		} else System.out.println(local_log + "Importing DSL keywords for the first time...");
		
		try {
			Ontologies.ParseOntologies(pathslist); //If there are no errors, the file was generated
		} catch (IOException e) {
			System.out.println(local_log + e.message);
			error(e.message, m.imports.last, SeMLPackage.Literals.IMPORT__NAME); //Error while loading or parsing ontology
			return false;
		}   	
		return true;
	}
	
}
